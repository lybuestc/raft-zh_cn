* 问：为什么有了commitIndex还要有个lastApplied
    * 日志不断append,会增加matchIndex，leader上根据matchIndex的副本数确定commitIndex,随着日志不断复制commitIndex也一直在前进。已经commit的日志要及时apply到状态机，即对客户端可见，applyIndex是已经apply到状态机的日志索引，它的值小于等于commitIndex，因为只有已经提交的日志才可以apply到状态机，applyIndex会紧跟者commitIndex往前走。以免客户端从状态机中查询数据时数据不太实时。
    * 那既然lastApplied是一直在追着commitIndex往前走，能不能直接用commitIndex来代替applyIndex呢，答案是不能。commitIndex可以理解为数据副本维度的定义，wal能保障提交就往前推进了。但是我们实现系统时其实还需要将wal log apply到真实系统的状态机中，比如mq领域的索引构建，数据库领域的数据变更等以供客户端可见，因此apply控制能看见的最大index,大于这个lastApplied的数据是不让读的，通过这样两个位置，我们就将可读的位置和副本同步进度两个环节完全解耦了，commitIndex只要复制了就往前推进，而每台机器上异步的进行apply并更新lastApplied。如果只用一个commitIndex，那我们需要等到所有大多数机器都apply了才能往前推进复制下一条，这是不合理的。

* 问：leader 将一条entry commit时，需要同步调用多个follower调用commit后才返回给客户端吗？如果不需要，那返回给用户响应了，但另外的follower没有commit这个log怎么办（引申到每个角色分别是怎么维护commitIndex的，以及为什么leader 返回了commit就能肯定不会被覆盖，即图8的case即解决方案，再隐身到no-op保障及时commit）
    * 答：不需要，每台机器上都会维护单机的commitIndex，不过变更逻辑不一样，leader上的commitIndex通过matchIndex中多数派都大于n来更新。 follower上的commitIndex通过接收来自leader的commitIndex来更新自己的commitIndex并apply，由apply确定数据的可见进度。

* 问：解释下图8的case
    * 答：虽然entry 2在图c中已经复制了3副本，但是不能直接commit，否则3成为leader就直接将已commit的2覆盖了，造成了日志回退。 按论文所述，因为当前leader的任期为3，我们不能commit term比当前leader的term小的entry,因此此时就算S1是leader，entry 2有3份，我们也不能commit,所以要么会演化成图d状态，要么演化成e状态，由term 4来帮助commit entry2.

* 问：raft会不会将已经写入到大多数实例上的entry回滚掉？什么场景？
    * 答：会，只有commit后才是安全的，没有commit就有可能。比如原论文中的图8 case。图c复制了3分entry2,如果此时S5又被选为leader将覆盖之前的entry2。其保障的并不是复制了多数派后即肯定会达到一致，是指必须commit完, commit后怎么防止图d的场景呢，就是加了一条commit约束，不能commit term比当前leader的term小的Entry，从而图c中的entry2是不会被提交的，只有有了entry4才会被附带着commit.这时候entry2才能确保不会被覆盖了。 简单来说entry2要么是在d场景中被覆盖，写入方并不会收到entry2 commit的响应；要么是需要等到entry4 commit时附带着将entry2 commit了再响应。总结下来就是raft保障的是commit动作的一致性，而不是uncommit log的一致性，复制到多个实例，只要没被commit，是可能被覆盖掉的，关键点就是commit后，响应给客户端后，就不能被覆盖了。
    
* 问：在图8中 c场景 leader commit了，但是另外两台还没commit就挂了，后续状态机是怎么继续运转的？
    * 答： 每次新选一个leader后发一个no-op日志，会附带着将上一任term的leader未commit的entry进行提交

* 问：leader是收到了多数副本写入持久话日志时即可返回给客户端吗?
    * 答：不是，只写入了wal可能还会造成重新选举后日志被回滚(图8 case)，返回客户端必须是日志commit后才返回的。
    
* 问：能否commit能直接数一个entry的副本数吗?
    * 不能直接数副本数，数副本就提交需限定在当前leader term大于等于entry 中的term，否则会出现回滚已commit数据的问题，因此小于当前leader term的 uncommit log不能直接commit, 需要借助新term的log附带着一起commit了。

* 问：什么时候响应给client, commit后，apply后？
    * 答：如果收到来自客户端的请求, 向本地日志追加条目并向所有服务器发送AppendEntries RPC, 在收到大多数响应后将该条目应用到状态机并回复响应给客户端。commit表示多副本存储了，leader自己apply就可以告诉客户端了，客户端如果再次来leader读是能读到最新数据的，如果去follower读，可以hang住直到follower 的apply追上。这里细节参考一致性读的设计。

* 问：raft如何线性一致读?
    * https://www.sofastack.tech/projects/sofa-jraft/consistency-raft-jraft/

* 问：Raft 引入 no-op 的作用
    * 答：为了让没有commit的数据在leader重新选举后后进行一次commit，否则比如leader刚要commit结果挂了，然后又选了个新leader,之前的数据还没commit，而为了防止覆盖掉已commit的数据，raft要求不能主动commit term小于当前leader term的entry(图8 case),因此每次选举个leader后追加个no-op操作来捎带着提交上一个term的leader没有commit的entry.
    https://www.ijkxs.com/3080.html

* 问：commitIndex和lastApplied是怎么维护的      
    * commitIndex表示当前已经提交的日志，也就是成功同步到大多数的日志位置的最大值，通过matchIndex计算而来。
    * commitIndex和applyIndex不需要存储，能够直接算出来，多数节点的matchIndex即为commitIndex。
    * apply一直在追commit的进度，只要多数副本已存储(即收到leader的commitIndex比当前的的大)，则跟进commitIndex并apply状态。
  
* 问：如图10，当3节点变成5节点，老的3个节点可以通过其中2个选出leader, 新加的2个节点可以和其中一个老的节点选举出另外一个leader,这个过程中一致性怎么保障？
  * 答：通过Cold-Cnew的共同一致机制保障，配置的变更通过2阶段提交实现。参考论文图11，领导人首先创建了 C-old,new 的配置条目在自己的日志中，并提交到 C-old,new 中（C-old 的大多数和 C-new 的大多数）。然后他创建 C-new 条目并提交到 C-new 中的大多数。在Cold,new提交前，Cold能独立决策从户leader；在Cold,new提交后到Cnew提交前，这个阶段需要在两个集合中的major中均达成一致；在Cnew提交后，则会只通过Cnew达成一致了。这样就不存在 C-new 和 C-old 可以同时做出决定的时间点。
    当Cnew提交后，如果leader不在Cnew中，则需要主动转换为follower,因此会存在一段时间是leader不属于Cnew，但是作为leader管理着集群，他复制日志但是不把他自己算作是大多数之一，当 C-new 被提交时，会发生领导人过渡，不在Cnew的老leader主动退出。

* 问：比如老节点是1，2，3，其中1为leader，而新节点是2，3，4，并不包括1，描述下这个leader切换过程?
  * 答：见上面Cold-Cnew的共同一致机制。在共同一致变更的中间状态，leader可能变成了2(通过2，3，4选举)，也可能一直维持1(通过1，2，3选举)，自从收到了Cold-Cnew配置，就立马按新配置决策，所以收到新配置的节点需(1,2,3),(2,3,4)中的两个major都投票，因此一直是一致的，1因为不属于Cnew, 在Cnew提交后主动退位（因为新的Cnew再也投票不出来1节点了）。
  
* 问：3节点切换5节点过程中，新加入的节点还没有历史数据，导致Cold->Cnew达成共同一致的过程时间很长，那么这么长一段时间怎么办?
  * 答：Raft 在配置更新之前使用了一种额外的阶段，在这个阶段，新的服务器以没有投票权身份加入到集群中来（领导人复制日志给他们，但是不考虑他们是大多数）。一旦新的服务器追赶上了集群中的其他机器，才开始进行Cold->Cnew的共同一致切换。

* 问：移除了不在Cnew中的服务器，干扰了后续的leader,怎么解决？
  * 答：比如老节点是1，2，3，其中1为leader，而新节点是2，3，4，当2当选了leader并切换为Cnew配置后，因为并不认识Cold中的1节点，所以不会给他发心跳，1发现leader 2没给他发心跳，就会发起更高term的请求，导致leader 2又主动转换为follower开启下一次的选举，这个状态如此往复，导致系统可用性大幅降低。
    为了避免这个问题，当服务器确认当前leader存在时，会忽略请求头皮的rpc。当服务器在当前最小选举超时时间内收到请求投票rpc，他不会更新当前任期号或投票，每个服务在开始一次选举前，至少等待一个最小选举超时时间，有利于避免被移除的服务器扰乱。然后择机关闭掉节点1即可。